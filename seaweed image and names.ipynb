{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "다운완료\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "driver = '/home/sky/다운로드/chromedriver'\n",
    "    \n",
    "browser = webdriver.Chrome(driver)\n",
    "\n",
    "\n",
    "def crawl(pageNo):\n",
    "    time.sleep(12)    \n",
    "    browser.get(\"https://www.nifs.go.kr/frcenter/resource/?sort=col_loc_dat&order=desc&curPage={}&new_input=no&res_type_cd=MOR&mf_l_cls_cd=AP&mf_m_cls_cd=SW&mf_s_cls_cd=&cls_type_cd=&species_name=&keyword=&sort_by=col_loc_dat\".format(pageNo)) \n",
    "\n",
    "    search_name = '해조류'\n",
    "\n",
    "    time.sleep(20)\n",
    "        # 네크워크의 속도를 위해 걸어둔 sleep\n",
    "    html = browser.page_source\n",
    "        # 크롬 브라우저에서 현재 불러온 소스 코드를 가져옴\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "        # beautiful soup을 사용해서 html 코드를 검색할 수 있도록 설정\n",
    "\n",
    "        \n",
    "    url_name = \"https://www.nifs.go.kr\"    \n",
    "    \n",
    "    img_names_eng = []\n",
    "    img_names_kor = []\n",
    "    params = []\n",
    "    #이미지 찾기\n",
    "    imgList = soup.find_all(\"img\")\n",
    "    for im in imgList[5:15]:\n",
    "#         params 리스트 변수에 images url을 담음\n",
    "        full_url = url_name+ im[\"src\"]\n",
    "        params.append(full_url)\n",
    "\n",
    "        \n",
    "    #이미지 학명 가져오기\n",
    "    tdiList = soup.find_all(\"i\")\n",
    "    for id in tdiList:\n",
    "        img_names_eng.append(id.text)\n",
    "        \n",
    "\n",
    "    #이미지 한글명 가져오기\n",
    "    list_num = [3, 14, 25, 36, 47, 58, 69, 80, 91, 102]\n",
    "    tds = soup.select(\"td\")\n",
    "    for i in list_num:\n",
    "        img_names_kor.append(tds[i].text) #text만 가져오기\n",
    "        \n",
    "        \n",
    "\n",
    "    dir_name = \"./\" + search_name + '/'\n",
    "#     os.makedirs(dir_name)               #폴더가 없으면 실행 해 줘야 함\n",
    "    a = 0\n",
    "    b = random.randrange(1, 100000)\n",
    "    c = random.randrange(50000, 500000000)\n",
    "    for p in params:\n",
    "        # 다운받을 폴더경로 입력\n",
    "        urllib.request.urlretrieve(p , dir_name + img_names_eng[a] + \" \" + img_names_kor[a] + \" \" + str(a+b+c) + \".jpg\")\n",
    "        a = a + 1\n",
    "\n",
    "        \n",
    "for pageNo in range(145, 254):\n",
    "    crawl(pageNo)\n",
    "    print(pageNo)\n",
    "\n",
    "# 브라우저 창 닫기\n",
    "browser.quit()\n",
    "\n",
    "print(\"다운완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 마지막이미지 다운받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2cb78c1dd443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpageNo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m254\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mcrawl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageNo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageNo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2cb78c1dd443>\u001b[0m in \u001b[0;36mcrawl\u001b[0;34m(pageNo)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# 다운받을 폴더경로 입력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdir_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_names_eng\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_names_kor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "driver = '/home/sky/다운로드/chromedriver'\n",
    "    \n",
    "browser = webdriver.Chrome(driver)\n",
    "\n",
    "\n",
    "def crawl(pageNo):\n",
    "    time.sleep(12)    \n",
    "    browser.get(\"https://www.nifs.go.kr/frcenter/resource/?sort=col_loc_dat&order=desc&curPage={}&new_input=no&res_type_cd=MOR&mf_l_cls_cd=AP&mf_m_cls_cd=SW&mf_s_cls_cd=&cls_type_cd=&species_name=&keyword=&sort_by=col_loc_dat\".format(pageNo)) \n",
    "\n",
    "    search_name = '해조류'\n",
    "\n",
    "    time.sleep(20)\n",
    "        # 네크워크의 속도를 위해 걸어둔 sleep\n",
    "    html = browser.page_source\n",
    "        # 크롬 브라우저에서 현재 불러온 소스 코드를 가져옴\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "        # beautiful soup을 사용해서 html 코드를 검색할 수 있도록 설정\n",
    "\n",
    "        \n",
    "    url_name = \"https://www.nifs.go.kr\"    \n",
    "    \n",
    "    img_names_eng = []\n",
    "    img_names_kor = []\n",
    "    params = []\n",
    "    #이미지 찾기\n",
    "    imgList = soup.find_all(\"img\")\n",
    "    for im in imgList[5:9]:\n",
    "#         params 리스트 변수에 images url을 담음\n",
    "        full_url = url_name+ im[\"src\"]\n",
    "        params.append(full_url)\n",
    "\n",
    "        \n",
    "    #이미지 학명 가져오기\n",
    "    tdiList = soup.find_all(\"i\")\n",
    "    for id in tdiList:\n",
    "        img_names_eng.append(id.text)\n",
    "        \n",
    "\n",
    "    #이미지 한글명 가져오기\n",
    "    list_num = [3, 14, 25, 36]\n",
    "    tds = soup.select(\"td\")\n",
    "    for i in list_num:\n",
    "        img_names_kor.append(tds[i].text) #text만 가져오기\n",
    "        \n",
    "        \n",
    "\n",
    "    dir_name = \"./\" + search_name + '/'\n",
    "#     os.makedirs(dir_name)              #폴더가 없으면 폴더 생성해줘야 함\n",
    "    a = 0\n",
    "    b = random.randrange(1, 100000)\n",
    "    c = random.randrange(50000, 500000000)\n",
    "    for p in params:\n",
    "        # 다운받을 폴더경로 입력\n",
    "        urllib.request.urlretrieve(p , dir_name + img_names_eng[a] + \" \" + img_names_kor[a] + \" \" + str(a+b+c) + \".jpg\")\n",
    "        a = a + 1\n",
    "\n",
    "        \n",
    "for pageNo in range(254, 255):\n",
    "    crawl(pageNo)\n",
    "    print(pageNo)\n",
    "\n",
    "# 브라우저 창 닫기\n",
    "browser.quit()\n",
    "\n",
    "print(\"다운완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
